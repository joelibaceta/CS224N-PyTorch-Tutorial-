{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89611951-b852-49da-bb4e-a14bfa143d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Import pprint, module we use for making our print statements prettier\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cfc3a4-c9be-45ec-b92c-eee378e97b2a",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4cc17b-7ff5-4807-af78-e18087710e16",
   "metadata": {},
   "source": [
    "## Tensor Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891aae3e",
   "metadata": {},
   "source": [
    "### From a Python List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5cf95f6-5a1b-4950-b745-827a87e54237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a tensor from a Python List\n",
    "data = [\n",
    "        [0, 1], \n",
    "        [2, 3],\n",
    "        [4, 5]\n",
    "       ]\n",
    "x_python = torch.tensor(data)\n",
    "\n",
    "# Print the tensor\n",
    "x_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e30e466-f9db-46f7-9242-c0bbd2dd0867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are using the dtype to create a tensor of particular type\n",
    "x_float = torch.tensor(data, dtype=torch.float)\n",
    "x_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95352e5a-3aed-418b-8467-1def664f57b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are using the dtype to create a tensor of particular type\n",
    "x_bool = torch.tensor(data, dtype=torch.bool)\n",
    "x_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dfcb59e-f95a-4e8a-828f-238fe44af81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_python.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bcaac3e-0f19-4c1c-9eff-c5180395601d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `torch.Tensor` defaults to float\n",
    "# Same as torch.FloatTensor(data)\n",
    "x = torch.Tensor(data) \n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f74a982",
   "metadata": {},
   "source": [
    "### From a NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b33780b9-011b-4542-b79b-cb9e8d2d711f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize a tensor from a NumPy array\n",
    "ndarray = np.array(data)\n",
    "x_numpy = torch.from_numpy(ndarray)\n",
    "\n",
    "# Print the tensor\n",
    "x_numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbf6dd2",
   "metadata": {},
   "source": [
    "### From a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b474b26-bcc5-40fc-8bd3-018246d96a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a base tensor\n",
    "x = torch.tensor([[1., 2.], [3., 4.]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f13867ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a tensor of 0s\n",
    "x_zeros = torch.zeros_like(x)\n",
    "x_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da5fe26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a tensor of 1s\n",
    "x_ones = torch.ones_like(x)\n",
    "x_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f0948c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1322, 0.0682],\n",
       "        [0.0599, 0.9042]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a tensor where each element is sampled from a uniform distribution\n",
    "# between 0 and 1\n",
    "x_rand = torch.rand_like(x)\n",
    "x_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62d5651d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0542, 0.4742],\n",
       "        [0.5360, 1.4363]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a tensor where each element is sampled from a normal distribution\n",
    "x_randn = torch.randn_like(x)\n",
    "x_randn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd76acf",
   "metadata": {},
   "source": [
    "### By Specifying a Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5c79cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a 2x3x2 tensor of 0s\n",
    "shape = (4, 2, 2)\n",
    "x_zeros = torch.zeros(shape) # x_zeros = torch.zeros(4, 3, 2) is an alternative\n",
    "x_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dac570",
   "metadata": {},
   "source": [
    "### With torch.arange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f300e0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with values 0-9\n",
    "x = torch.arange(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0a5590",
   "metadata": {},
   "source": [
    "### Tensor Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a182569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DType Property \n",
    "\n",
    "# Initialize a 3x2 tensor, with 3 rows and 2 columns\n",
    "x = torch.ones(3, 2)\n",
    "x.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81f5a137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "# Initialize a 3x2 tensor, with 3 rows and 2 columns\n",
    "x = torch.Tensor([[1, 2], [3, 4], [5, 6]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4846c540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out its shape\n",
    "# Same as x.size()\n",
    "x.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd305638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the number of elements in a particular dimension\n",
    "# 0th dimension corresponds to the rows\n",
    "x.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be8472d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the size of the 0th dimension\n",
    "x.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "848e4a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example use of view()\n",
    "# x_view shares the same memory as x, so changing one changes the other\n",
    "x_view = x.view(3, 2)\n",
    "x_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aab06024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can ask PyTorch to infer the size of a dimension with -1\n",
    "x_view = x.view(-1, 3)\n",
    "x_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d47566f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the shape of x to be 3x2\n",
    "# x_reshaped could be a reference to or copy of x\n",
    "x_reshaped = torch.reshape(x, (2, 3))\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a6cc2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a 5x2 tensor, with 5 rows and 2 columns\n",
    "x = torch.arange(10).reshape(5, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba0623f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new dimension of size 1 at the 1st dimension\n",
    "x = x.unsqueeze(1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08e91adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1]],\n",
       "\n",
       "        [[2, 3]],\n",
       "\n",
       "        [[4, 5]],\n",
       "\n",
       "        [[6, 7]],\n",
       "\n",
       "        [[8, 9]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbf1b2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of elements in tensor.\n",
    "x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8871c350",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f38df889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an example tensor\n",
    "x = torch.Tensor([[1, 2], [3, 4]])\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0be27e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the device of the tensor\n",
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b755cc",
   "metadata": {},
   "source": [
    "We can move a tensor from one device to another with the method to(device)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4eb44737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, using CPU\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available, if so, move the tensor to the GPU\n",
    "if torch.cuda.is_available():\n",
    "    x.to('cuda')\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")\n",
    "    x.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4575cb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e22c14",
   "metadata": {},
   "source": [
    "## Tensor Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d29ce775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.],\n",
       "         [ 3.,  4.]],\n",
       "\n",
       "        [[ 5.,  6.],\n",
       "         [ 7.,  8.]],\n",
       "\n",
       "        [[ 9., 10.],\n",
       "         [11., 12.]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an example tensor\n",
    "x = torch.Tensor([\n",
    "                  [[1, 2], [3, 4]],\n",
    "                  [[5, 6], [7, 8]], \n",
    "                  [[9, 10], [11, 12]] \n",
    "                 ])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87f8e741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c460930b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the 0th element, which is the first row\n",
    "x[0] # Equivalent to x[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2b8a0b",
   "metadata": {},
   "source": [
    "We can also index into multiple dimensions with :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56292a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 5., 9.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top left element of each element in our tensor\n",
    "x[:, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4218fa",
   "metadata": {},
   "source": [
    "We can also access arbitrary elements in each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4922bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.],\n",
       "         [ 3.,  4.]],\n",
       "\n",
       "        [[ 5.,  6.],\n",
       "         [ 7.,  8.]],\n",
       "\n",
       "        [[ 9., 10.],\n",
       "         [11., 12.]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print x again to see our tensor\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc20eda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[5., 6.],\n",
       "         [7., 8.]],\n",
       "\n",
       "        [[5., 6.],\n",
       "         [7., 8.]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's access the 0th and 1st elements, each twice\n",
    "i = torch.tensor([0, 0, 1, 1])\n",
    "x[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6923d761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's access the 0th elements of the 1st and 2nd elements\n",
    "i = torch.tensor([1, 2])\n",
    "j = torch.tensor([0])\n",
    "x[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5180fd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2b3d3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, 0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c79b8c",
   "metadata": {},
   "source": [
    "## Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a61f39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an example tensor\n",
    "x = torch.ones((3,2,2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f8f9801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 3.],\n",
       "         [3., 3.]],\n",
       "\n",
       "        [[3., 3.],\n",
       "         [3., 3.]],\n",
       "\n",
       "        [[3., 3.],\n",
       "         [3., 3.]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform elementwise addition\n",
    "# Use - for subtraction\n",
    "x + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31187ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2.],\n",
       "         [2., 2.]],\n",
       "\n",
       "        [[2., 2.],\n",
       "         [2., 2.]],\n",
       "\n",
       "        [[2., 2.],\n",
       "         [2., 2.]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform elementwise multiplication\n",
    "# Use / for division\n",
    "x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01028cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 4x3 tensor of 6s\n",
    "a = torch.ones((4,3)) * 6\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e1478a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 1D tensor of 2s\n",
    "b = torch.ones(3) * 2\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea9bf174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide a by b\n",
    "a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b53722e",
   "metadata": {},
   "source": [
    "We can use tensor.matmul(other_tensor) for matrix multiplication and tensor.T for transpose. Matrix multiplication can also be performed with @."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d6d02c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([36., 36., 36., 36.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative to a.matmul(b)\n",
    "# a @ b.T returns the same result since b is 1D tensor and the 2nd dimension\n",
    "# is inferred\n",
    "a @ b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6fb04dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(a.shape)\n",
    "pp.pprint(a.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c123961",
   "metadata": {},
   "source": [
    "We can take the mean and standard deviation along a certain dimension with the methods mean(dim) and std(dim). That is, if we want to get the mean 3x2 matrix in a 4x3x2 matrix, we would set the dim to be 0. We can call these methods with no parameter to get the mean and standard deviation for the whole tensor. To use mean and std our tensor should be a floating point type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e45322e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Mean: 2.5'\n",
      "'Mean in the 0th dimension: tensor([2.5000, 2.5000])'\n",
      "'Mean in the 1st dimension: tensor([1., 2., 3., 4.])'\n"
     ]
    }
   ],
   "source": [
    "# Create an example tensor\n",
    "m = torch.tensor(\n",
    "    [\n",
    "     [1., 1.],\n",
    "     [2., 2.],\n",
    "     [3., 3.],\n",
    "     [4., 4.]\n",
    "    ]\n",
    ")\n",
    "\n",
    "pp.pprint(\"Mean: {}\".format(m.mean()))\n",
    "pp.pprint(\"Mean in the 0th dimension: {}\".format(m.mean(0)))\n",
    "pp.pprint(\"Mean in the 1st dimension: {}\".format(m.mean(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbc6b9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: torch.Size([4, 3])\n",
      "Shape after concatenation in dimension 0: torch.Size([12, 3])\n",
      "Shape after concatenation in dimension 1: torch.Size([4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate in dimension 0 and 1\n",
    "a_cat0 = torch.cat([a, a, a], dim=0)\n",
    "a_cat1 = torch.cat([a, a, a], dim=1)\n",
    "\n",
    "print(\"Initial shape: {}\".format(a.shape))\n",
    "print(\"Shape after concatenation in dimension 0: {}\".format(a_cat0.shape))\n",
    "print(\"Shape after concatenation in dimension 1: {}\".format(a_cat1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "251ac9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print our tensor\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b55d889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.],\n",
       "        [6., 6., 6.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add() is not in place\n",
    "a.add(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc495d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 12., 12.],\n",
       "        [12., 12., 12.],\n",
       "        [12., 12., 12.],\n",
       "        [12., 12., 12.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add_() is in place\n",
    "a.add_(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed31c05",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04319254",
   "metadata": {},
   "source": [
    "PyTorch and other machine learning libraries are known for their automatic differantiation feature. That is, given that we have defined the set of operations that need to be performed, the framework itself can figure out how to compute the gradients. We can call the backward() method to ask PyTorch to calculate the gradiends, which are then stored in the grad attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "983a163a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create an example tensor\n",
    "# requires_grad parameter tells PyTorch to store gradients\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "\n",
    "# Print the gradient if it is calculated\n",
    "# Currently None since x is a scalar\n",
    "pp.pprint(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32b0cd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12.])\n"
     ]
    }
   ],
   "source": [
    "# Calculating the gradient of y with respect to x\n",
    "y = x * x * 3 # 3x^2\n",
    "y.backward()\n",
    "pp.pprint(x.grad) # d(y)/d(x) = d(3x^2)/d(x) = 6x = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124b8b17",
   "metadata": {},
   "source": [
    "Let's run backprop from a different tensor again to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a912eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24.])\n"
     ]
    }
   ],
   "source": [
    "z = x * x * 3 # 3x^2\n",
    "z.backward()\n",
    "pp.pprint(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2780d1",
   "metadata": {},
   "source": [
    "## Neural Network Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "92f5ad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a48794",
   "metadata": {},
   "source": [
    "### Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5497d70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4326,  1.0321],\n",
       "         [-0.4326,  1.0321],\n",
       "         [-0.4326,  1.0321]],\n",
       "\n",
       "        [[-0.4326,  1.0321],\n",
       "         [-0.4326,  1.0321],\n",
       "         [-0.4326,  1.0321]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the inputs\n",
    "input = torch.ones(2,3,4)\n",
    "\n",
    "# Make a linear layers transforming N,*,H_in dimensinal inputs to N,*,H_out\n",
    "# dimensional outputs\n",
    "linear = nn.Linear(4, 2)\n",
    "linear_output = linear(input)\n",
    "linear_output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cc5d35",
   "metadata": {},
   "source": [
    "### Other Module Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4397f",
   "metadata": {},
   "source": [
    "There are several other preconfigured layers in the nn module. Some commonly used examples are nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm1d, nn.BatchNorm2d, nn.Upsample and nn.MaxPool2d among many others. We will learn more about these as we progress in the course. For now, the only important thing to remember is that we can treat each of these layers as plug and play components: we will be providing the required dimensions and PyTorch will take care of setting them up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c086d61",
   "metadata": {},
   "source": [
    "### Activation Function Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "607c6778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4326,  1.0321],\n",
       "         [-0.4326,  1.0321],\n",
       "         [-0.4326,  1.0321]],\n",
       "\n",
       "        [[-0.4326,  1.0321],\n",
       "         [-0.4326,  1.0321],\n",
       "         [-0.4326,  1.0321]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6083f9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3935, 0.7373],\n",
       "         [0.3935, 0.7373],\n",
       "         [0.3935, 0.7373]],\n",
       "\n",
       "        [[0.3935, 0.7373],\n",
       "         [0.3935, 0.7373],\n",
       "         [0.3935, 0.7373]]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "output = sigmoid(linear_output)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223f525f",
   "metadata": {},
   "source": [
    "### Putting the Layers Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16018811",
   "metadata": {},
   "source": [
    "So far we have seen that we can create layers and pass the output of one as the input of the next. Instead of creating intermediate tensors and passing them around, we can use nn.Sequentual, which does exactly that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c20d3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4219, 0.3491],\n",
       "         [0.4219, 0.3491],\n",
       "         [0.4219, 0.3491]],\n",
       "\n",
       "        [[0.4219, 0.3491],\n",
       "         [0.4219, 0.3491],\n",
       "         [0.4219, 0.3491]]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = nn.Sequential(\n",
    "    nn.Linear(4, 2),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "input = torch.ones(2,3,4)\n",
    "output = block(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b0897b",
   "metadata": {},
   "source": [
    "#### Custom Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "584111b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    # Call to the __init__ function of the super class\n",
    "    super(MultilayerPerceptron, self).__init__()\n",
    "\n",
    "    # Bookkeeping: Saving the initialization parameters\n",
    "    self.input_size = input_size \n",
    "    self.hidden_size = hidden_size \n",
    "\n",
    "    # Defining of our model\n",
    "    # There isn't anything specific about the naming of `self.model`. It could\n",
    "    # be something arbitrary.\n",
    "    self.model = nn.Sequential(\n",
    "        nn.Linear(self.input_size, self.hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(self.hidden_size, self.input_size),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    output = self.model(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "603ceac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    # Call to the __init__ function of the super class\n",
    "    super(MultilayerPerceptron, self).__init__()\n",
    "\n",
    "    # Bookkeeping: Saving the initialization parameters\n",
    "    self.input_size = input_size \n",
    "    self.hidden_size = hidden_size \n",
    "\n",
    "    # Defining of our layers\n",
    "    self.linear = nn.Linear(self.input_size, self.hidden_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.linear2 = nn.Linear(self.hidden_size, self.input_size)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "  def forward(self, x):\n",
    "    linear = self.linear(x)\n",
    "    relu = self.relu(linear)\n",
    "    linear2 = self.linear2(relu)\n",
    "    output = self.sigmoid(linear2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765857d",
   "metadata": {},
   "source": [
    "Now that we have defined our class, we can instantiate it and see what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6aeb4a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5514, 0.3762, 0.4956, 0.3232, 0.5243],\n",
       "        [0.5711, 0.5383, 0.4982, 0.3363, 0.3744]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a sample input\n",
    "input = torch.randn(2, 5)\n",
    "\n",
    "# Create our model\n",
    "model = MultilayerPerceptron(5, 3)\n",
    "\n",
    "# Pass our input through our model\n",
    "model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6d2203b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('linear.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.4041,  0.1791, -0.3538, -0.2695,  0.4321],\n",
       "          [ 0.2490, -0.3557, -0.3299, -0.0379,  0.3613],\n",
       "          [-0.3564, -0.2623,  0.3753, -0.1224, -0.1645]], requires_grad=True)),\n",
       " ('linear.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0296, 0.3683, 0.0535], requires_grad=True)),\n",
       " ('linear2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1015,  0.0289, -0.0413],\n",
       "          [ 0.5406,  0.5114, -0.3159],\n",
       "          [ 0.2199, -0.4689, -0.2090],\n",
       "          [-0.5578, -0.1032, -0.4478],\n",
       "          [-0.1840, -0.4108,  0.5023]], requires_grad=True)),\n",
       " ('linear2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.2353, -0.2842,  0.1289, -0.4250, -0.2547], requires_grad=True))]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384b7a37",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c6032",
   "metadata": {},
   "source": [
    "We have showed how gradients are calculated with the backward() function. Having the gradients isn't enought for our models to learn. We also need to know how to update the parameters of our models. This is where the optomozers comes in. torch.optim module contains several optimizers that we can use. Some popular examples are optim.SGD and optim.Adam. When initializing optimizers, we pass our model parameters, which can be accessed with model.parameters(), telling the optimizers which values it will be optimizing. Optimizers also has a learning rate (lr) parameter, which determines how big of an update will be made in every step. Different optimizers have different hyperparameters as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "05de65f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81768ca6",
   "metadata": {},
   "source": [
    "After we have our optimization function, we can define a loss that we want to optimize for. We can either define the loss ourselves, or use one of the predefined loss function in PyTorch, such as nn.BCELoss(). Let's put everything together now! We will start by creating some dummy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c7b64943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5522,  1.2808,  0.5177,  1.1953,  1.3007],\n",
       "        [-0.2136,  1.8097,  1.9314, -0.2380,  0.2242],\n",
       "        [ 1.6737,  1.0757,  1.1377,  0.4370, -0.9362],\n",
       "        [ 1.3108,  3.3745,  2.1980,  0.6397,  0.3603],\n",
       "        [ 0.5579,  1.2647,  0.8169,  1.1712,  1.0324],\n",
       "        [ 0.5548, -0.3197,  0.3583,  0.7412,  0.7948],\n",
       "        [-0.0565,  2.8970,  2.3576,  1.8476,  0.5214],\n",
       "        [-0.2722,  1.2165,  1.2751,  0.9607,  2.7261],\n",
       "        [ 1.2929,  1.7935,  2.6197,  1.6742, -0.2893],\n",
       "        [ 1.7099,  0.3498,  1.3995,  2.2894, -0.4380]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the y data\n",
    "y = torch.ones(10, 5)\n",
    "\n",
    "# Add some noise to our goal y to generate our x\n",
    "# We want out model to predict our original data, albeit the noise\n",
    "x = y + torch.randn_like(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f602a180",
   "metadata": {},
   "source": [
    "Now, we can define our model, optimizer and the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8bc0e033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7217341065406799"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = MultilayerPerceptron(5, 3)\n",
    "\n",
    "# Define the optimizer\n",
    "adam = optim.Adam(model.parameters(), lr=1e-1)\n",
    "\n",
    "# Define loss using a predefined loss function\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "# Calculate how our model is doing now\n",
    "y_pred = model(x)\n",
    "loss_function(y_pred, y).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3089a07",
   "metadata": {},
   "source": [
    "Let's see if we can have our model achieve a smaller loss. Now that we have everything we need, we can setup our training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9665d0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: traing loss: 0.7217341065406799\n",
      "Epoch 1: traing loss: 0.5939948558807373\n",
      "Epoch 2: traing loss: 0.47342708706855774\n",
      "Epoch 3: traing loss: 0.34594619274139404\n",
      "Epoch 4: traing loss: 0.23017439246177673\n",
      "Epoch 5: traing loss: 0.14004084467887878\n",
      "Epoch 6: traing loss: 0.07889825105667114\n",
      "Epoch 7: traing loss: 0.042169179767370224\n",
      "Epoch 8: traing loss: 0.022025126963853836\n",
      "Epoch 9: traing loss: 0.011530808173120022\n"
     ]
    }
   ],
   "source": [
    "# Set the number of epoch, which determines the number of training iterations\n",
    "n_epoch = 10 \n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "  # Set the gradients to 0\n",
    "  adam.zero_grad()\n",
    "\n",
    "  # Get the model predictions\n",
    "  y_pred = model(x)\n",
    "\n",
    "  # Get the loss\n",
    "  loss = loss_function(y_pred, y)\n",
    "\n",
    "  # Print stats\n",
    "  print(f\"Epoch {epoch}: traing loss: {loss}\")\n",
    "\n",
    "  # Compute the gradients\n",
    "  loss.backward()\n",
    "\n",
    "  # Take a step to optimize the weights\n",
    "  adam.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "61594766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9992, 0.9995, 0.9972, 0.9997, 0.9933],\n",
       "        [0.9918, 0.9948, 0.9854, 0.9956, 0.9675],\n",
       "        [0.9871, 0.9916, 0.9798, 0.9927, 0.9560],\n",
       "        [0.9999, 0.9999, 0.9992, 1.0000, 0.9980],\n",
       "        [0.9990, 0.9994, 0.9967, 0.9996, 0.9922],\n",
       "        [0.9878, 0.9919, 0.9803, 0.9931, 0.9585],\n",
       "        [0.9999, 0.9999, 0.9991, 0.9999, 0.9978],\n",
       "        [0.9998, 0.9999, 0.9991, 0.9999, 0.9977],\n",
       "        [0.9996, 0.9998, 0.9983, 0.9999, 0.9959],\n",
       "        [0.9985, 0.9991, 0.9957, 0.9993, 0.9898]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how our model performs on the training data\n",
    "y_pred = model(x)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1520ee30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9975, 0.9985, 0.9937, 0.9988, 0.9854],\n",
       "        [0.9999, 0.9999, 0.9993, 1.0000, 0.9982],\n",
       "        [0.9875, 0.9919, 0.9803, 0.9930, 0.9571],\n",
       "        [1.0000, 1.0000, 0.9996, 1.0000, 0.9990],\n",
       "        [1.0000, 1.0000, 0.9998, 1.0000, 0.9995],\n",
       "        [0.9992, 0.9995, 0.9971, 0.9996, 0.9930],\n",
       "        [0.9997, 0.9999, 0.9987, 0.9999, 0.9968],\n",
       "        [1.0000, 1.0000, 0.9998, 1.0000, 0.9994],\n",
       "        [0.9952, 0.9970, 0.9900, 0.9976, 0.9774],\n",
       "        [1.0000, 1.0000, 0.9997, 1.0000, 0.9992]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create test data and check how our model performs on it\n",
    "x2 = y + torch.randn_like(y)\n",
    "y_pred = model(x2)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
